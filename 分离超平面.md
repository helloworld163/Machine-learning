我们看到线性判别分析和逻辑斯蒂回归都用类似但稍微不同的方式估计线性判定边界。本章的其余部分将介绍分离超平面分类法。

**感知学习算法** 

试图通过极小化误分类点到判别边界的距离来找出分离超平面。如果响应$y_i=1$ 被误分类，则$x_i^T \beta+\beta_0<0$ ，反之亦然。目标是极小化:$D（\beta,\beta_0)=-\sum\limits_{i\in \cal M}y_i (x_i^T \beta +\beta_0)$ 其中$\cal M$ 是误分类点的下标集。该算法使用随机梯度下降法来极小化该分段线性准则。

$$\binom{\beta_0}{\beta} \leftarrow \binom{\beta_0}{\beta} + \rho \binom{y_ix_i}{y_i}$$

但是这种方法当数据可分的时候，存在许多解，并且找到哪个解释依赖于初值的

“有限步”的步数可能很大，间隔越小，所需要的时间就越长

当数据不可分的时候，算法不收敛，而且呈现周期变化

**最佳分离超平面**

考虑优化问题：$\begin{align}& \max_{\beta,\beta_0,\|\beta\|=1} C \\ 受限于& y_i(x_i^T\beta+\beta_0) \geq C,i=1,…,N  \end{align}$

其等价于$\begin{align}& \min_{\beta,\beta_0} \frac{1}{2}\|\beta \|^2 \\ 受限于& y_i(x_i^T\beta+\beta_0) \geq C,i=1,…,N  \end{align}$ 

