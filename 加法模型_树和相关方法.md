本章主要是一些有指导学习的特定方法 ，这些方法对未知的归回函数假定一种结构化的形式，并且借此巧妙地解决了维数灾难。但是它们却不能详细地说明模型，因此在每一种情况下都必须做出权衡。

#### 广义加法模型

在回归的框架下，广义加法模型具有以下的形式：

$E(Y|X_1,X_2,…,X_p) = \alpha +f_1(X_1) + f_2(X_2) +…+ f_p(X_p) $ 

其中$\mathbf{X} $ 表示的是预测子，$\mathbf{Y} $ 是输出

在这里使用散点图光滑子拟合每一个函数，并且提供一个同时估计所有p个函数的算法

对于二分类问题，比如在二元数据的逻辑斯蒂回归模型中，通过线性回归模型和分对数连接函数：

$log(\frac{\mu(X)}{1-\mu(X)}) = \alpha + \beta_1 X_1 +… + \beta_p X_p $  将二元响应$\mu(X) = Pr(Y=1|X) $ 的均值与预测子联系起来

一般地，响应Y的条件均值$\mu(X) $ 通过连接函数$g$ ：

$g[\mu(X)] = \alpha + f_1(X_1) + … + f_p(X_p) $

连接函数的典型例子如下：

*  $g(\mu) = \mu$ 是恒等连接，用于高斯响应数据的线性模型和加法模型
*  $g(\mu) = logit(\mu) 或者g(\mu) = probit(\mu) $ ，概率单位连接函数，用于对二项式概率建模。概率的单位函数是逆高斯累积分布函数: $probit(\mu) = \phi^{-1} (\mu) $ 
*  $g(\mu) = log(\mu) 用于泊松计数数据的对数线性模型或者对数加法模型

这些函数都是源于指数族抽样模型，该族还包括$\gamma$ 分布和负二项分布。这些族产生了著名的广义线性模型。

我们可以轻易地将线性形式与其他参数形式的非线性项混合。当某些输入时定性的变量时，这是必要的。

##### 9.1.1拟合加法模型

加法模型有如下形式： $Y = \alpha + \sum\limits_{j=1} ^p  f_j(X_j) + \epsilon $ 

可以对该问题指定一个类似于罚平方和标准的形式：

$PRSS(\alpha , f_1,f_2,… , f_p) = \sum\limits_{i=1} ^N \{ y_i-\alpha-\sum\limits_{j=1}^p f_j(x_{ij}) \}^2 + \sum\limits_{j=1} ^p \lambda_j \int f''_j(t_j)^2 dt_j $ 

其中$\lambda$ 是调整参数，可以证明，每一个函数$f_j$ 是分量$X_j$ 上的三次样条。  



##### 基于树的方法

回归树：

通过寻找分割点来将区域进行分割，并且得到不同的区域。我们在建立树的同时需要考虑到树的复杂性结构。可以通过定义复杂度代价准则来进行评价。

分类树：

* 误分类误差： $\frac{1}{N_m} \sum\limits_{i\in R_m} I(y_i \neq k(m)) = 1- \hat p_{mk(m)} $ 
* Gini指数： $\sum\limits_{k=1} ^K \hat p_{mk} (1- \hat p_{mk}) $ 
* 交叉熵：$-\sum\limits_{k=1} ^K \hat p_{mk} \mathbf{log} \hat p_{mk} $ 

交叉熵和Gini指数是可微的

