对于许多应⽤来说，独⽴同分布的假设不成⽴。这⾥，我们考虑这样的数据集中的⼀个重要的类型，即描述了顺序数据的数据集。⽅便起见，我们有时会⽤“过去”观测或者“未来”观测来称呼某个观测。然⽽，本章中研究的模型同样适⽤于所有形式的顺序数据，⽽不仅仅是时间序列数据。

#### 马尔科夫模型

如果我们现在假设右侧的每个条件概率分布只与最近的⼀次观测有关，⽽独⽴于其他所有之前的观测，那么我们就得到了⼀阶马尔科夫链（ first-order Markov chain）：
$$
p(x_1,\dots ,x_N) = p(x_1) \sum\limits_{n=2}^N p(x_n|x_{n-1})
$$
在这种模型的⼤部分应⽤中，条件概率分布$p(x_n | x_{n−1})$被限制为相等的。我们可以类似地考虑扩展到M阶马尔科夫链，其中⼀个特定的变量依赖于前M个变量。

对于连续变量来说，我们可以使⽤线性⾼斯条件概率分布，其中每个结点都是⼀个⾼斯概率分布，均值是⽗结点的⼀个线性函数。这被称为⾃回归（ autoregressive）模型或者AR模型。另⼀种⽅法是为
$$
p(x_n | x_{n−M}, \dots , x_{n−1})
$$
使⽤参数化的模型，例如神经⽹络。这种⽅法有时被称为抽头延迟线（ tapped delay line），因为它对应于存储（延迟）观测变量的前⾯M个值来预测下⼀个值。

对于每个观测$x_n$，我们引⼊⼀个对应的潜在变量$z_n$（类型或维度可能与观测变量不同）。我们现在假设潜在变量构成了马尔科夫链，得到的图结构被称为状态空间模型（ state space model）。

如果潜在变量是离散的，那么我们得到了隐马尔科夫模型（ hidden Markov model）或者HMM；如果潜在变量和观测变量都是⾼斯变量（结点的条件概率分布对于⽗结点的依赖是线性⾼斯的形式），那么我们就得到了线性动态系统（ linear dynamical system）。

#### 隐马尔科夫模型

