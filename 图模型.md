#### 第17章

图模型：图包含顶点集合，以及连接顶点对的边的集合。在图模型中，每个顶点表示的是随机变量。并且图给出了理解整个随机变量的联合分布的可视化方法。网络结构是在假定多元高斯分布情况下利用本章后面要讨论的图$lasso$ 过程估计得到的

采用图模型的主要挑战是模型选择，从数据来估计边的参数，并且从联合分布中计算边缘顶点的概率和期望。也就是被称为是学习和推断

##### 马尔科夫图及其性质

* 从数据对边的参数的估计和参量化
* 估计图的拓扑结构

$$No edge joining X and Y \Leftrightarrow X \bot Y | reset$$ 

分离器具有良好的性质，它们将图分解成条件独立的部分。特别地，在含有$A,B,C$ 子图的图$\cal G$ 

$$ if \quad C \quad separates \quad A \quad B \quad then A \bot B |C$$  

称为全局马尔科夫性质，我们可以将图分解成团，一个团是完全子图（所有的顶点都与其他的点邻接的顶点集），如果一个团，没有其他顶点可以加进去，那么这个团被称为是最大团

在马尔科夫图$\cal G$ 上的概率密度函数$f$ 可以表示成

$$f(x) = \frac{1}{Z}  \prod _{C \in \cal c} \psi_C(x_C)$$ 其中正函数$\psi_C(\cdot)$ 被称为是团势



#### 连续变量的无向图模型

假定观测服从均值为$\mu$ ，协方差为$\Sigma$ 的多元高斯分布

协方差矩阵的逆$\Sigma^{-1}$ 包含变量之间的偏协方差信息，如果其第$ij$ 个元素为0，那么变量$i,j$ 在其他变量给定的情况下是独立的

**图结构已知时候参数的估计**

实验的协方差矩阵$$S=\frac{1}{N} \sum\limits_{i=1}^N (x_i-\overline{x})(x_i-\overline{x})^T$$ 



**离散变量的无向图模型** 

二值变量的成对马尔科夫网络更加流行，在机器学习领域被称为是玻尔兹曼机

用$X_j$ 来标记节点$j$ 的二值变量。它们的联合分布$Ising$ 模型由下式给出

$$p(X,\Theta)=exp[\sum\limits_{(j,k)\in E} \theta_{jk} X_j X_k -\Phi(\Theta)]  for X \in \cal X$$ 

**隐藏节点**

我们可以通过包含潜在或者隐藏节点来增加离散马尔科夫 网络的复杂性。假设变量的子集$X_{\cal H}$ 是未被观测的或者是隐藏的。剩余的变量$X_{\cal v}$ 是可见的。

玻尔兹曼以及马尔科夫网络在计算上主要是通过计算 最大化所有的可见单元的联合分布的对数似然。可以使用隐藏单元对特征向量的结构进行建模

观测数据的对数似然函数是：

$$\begin{align} \cal l (\Theta) & = \sum\limits_{i=1}^N log[Pr_{\Theta}(X_{\nu} = x_{i\nu})] \\ &= \sum\limits_[log \sum\limits_{x_H \in X_H} exp \sum\limits_{(j,k)\in E} (\theta_{jk}x_{ij} x_{jk}-\Phi(\Theta))] \end{align} $$ 

$$\Theta = \Sigma ^{-1}$$ 捕捉了所有的二阶信息，是描述每个顶点在给定剩余点时候的条件分布需要的信息。也被称为是高斯图模型的“自然”参数

