专家的分层混合(HME)过程可以看成是基于树方法的变种。主要的差异是树的分割不是硬的决定，而是软概率的决定。在每个结点一个观测往左或者往右的概率取决于输入值。因为最后的参数优化问题是光滑的，所以有一些计算的优势，不像在基于树的方式中的离散分割点的搜索。软分割或许也可以帮助预测准确性，并且提供另外一种有用的数据描述方式。

终止结点称为专家(experts)，非终止结点称为门控网络(gating networks)。想法是，每个专家对响应提供一个看法(预测)，并且这些通过门控网络结合在一起。正如我们所见，这个模型正式上是混合模型，并且图中的两层模型可以推广为多层次，因此有了名字专家的分层混合(hierarchical mixtures of experts)

HME中顶层的门控网络：
$$
g_j(x ,\gamma_j) = \frac{e^{r_j^T x}}{\sum\limits_{k=1}^K e^{\gamma_k^T x}}
$$
第二层的门控网络有类似的形式：
$$
g_{l|j}(x ,\gamma_{jl}) = \frac{e^{r_{jl}^T x}}{\sum\limits_{k=1}^K e^{\gamma_{jk}^T x}}
$$
在每个终止结点的模型：
$$
Y \sim Pr(y|x ,\theta_{jl})
$$
