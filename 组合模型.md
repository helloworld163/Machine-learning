经常发现的⼀件事情是，我们可以通过以某种⽅式将多个模型结合到⼀起的⽅法来提升性能，⽽不是独⽴
地使⽤⼀个单独的模型。

* 委员会⽅法的⼀个重要的变体，被称为提升⽅法（ boosting）。这种⽅法按顺序训练多个模型，其中⽤来训练⼀个特定模型的误差函数依赖于前⼀个模型的表现。
* 另⼀种形式的模型组合是选择⼀个模型进⾏预测，其中模型的选择是输⼊变量的⼀个函数。因此不同的模型⽤于对输⼊空间的不同的区域进⾏预测。这种⽅法的⼀种⼴泛使⽤的框架被称为决策树（ decision tree）.

#### 贝叶斯模型平均

模型包含⼀个⼆值潜在变量z，它表⽰混合分布中的哪个分量⽤于⽣成对应的数据点。因此，模型通过联合概率分布 $p(x, z)$进⾏具体化.这个在h上的求和式的意义是，只有⼀个模型⽤于⽣成整个数据集， h上的概率分布仅仅反映了我们对于究竟是哪个模型⽤于⽣成数据的不确定性。

构建⼀个委员会的最简单的⽅法是对⼀组独⽴的模型的预测取平均。这种观点考虑偏置和⽅差之间的折中，它将模型的误差分解为偏置分量和⽅差分量。



